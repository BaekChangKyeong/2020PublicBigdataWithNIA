{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 import\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import pandas as pd\n",
    "import lxml.html\n",
    "from selenium.webdriver import Chrome, Firefox\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀 저장 함수 정의\n",
    "def save_excel(df):\n",
    "    excel = pd.ExcelWriter('../data/BlueHouse.xlsx')\n",
    "    df.to_excel(excel, '.', index=False)\n",
    "    excel.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전역 변수 선언 (전체 레코드가 병합될 데이터프레임, 전체 레코드가 저장될 리스트, 각 레코드를 저장할 임시 리스트)\n",
    "df = pd.DataFrame({'번호':[], '분류':[], '제목':[], '만료일':[], '참여인원':[]})\n",
    "my_list = []\n",
    "temp_str_list = ['' for x in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롬드라이버 권한 설정 변경 (크롬드라이버는 구글에서 다운로드 가능)\n",
    "os.chmod('../chromedriver', 755)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 셀레니움 웹드라이버 옵션 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹드라이버 브라우저 열기\n",
    "browser = webdriver.Chrome('/Users/jaehyeob/venv_02/CrawlingScraping/chromedriver', options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 ~ 20 페이지 크롤링 (하나의 세션에서 5분 내에 25페이지를 초과해서 접근할 경우 세션 에러 발생)\n",
    "# 따라서, 5분 간격으로 1~20, 21~40, 41~60, 61~80, 81~100 페이지 따로 크롤링 진행하였음\n",
    "page_num = 1\n",
    "\n",
    "while page_num <= 20:\n",
    "    url = 'https://www1.president.go.kr/petitions/?c=0&only=1&page={}&order=1'.format(page_num)\n",
    "\n",
    "    # 해당 url 열기\n",
    "    browser.get(url)\n",
    "    # 로딩 시간 고려해서 대기 시간 설정\n",
    "    browser.implicitly_wait(5)\n",
    "\n",
    "    # xpath 사용해서 tag 검색으로 elements 불러오기\n",
    "    lis = browser.find_elements_by_xpath('//*[@id=\"cont_view\"]/div[2]/div/div/div[2]/div[2]/div[4]/div/div[2]/div[2]/ul/li')\n",
    "    \n",
    "    # 모든 element에 대하여\n",
    "    for li in lis:\n",
    "        # tag 사이의 text를 개행 기준으로 나눠서 임시 리스트에 저장\n",
    "        temp_str_list = li.text.split('\\n')\n",
    "        # 임시 리스트를 전체 리스트에 추가\n",
    "        my_list.append(pd.DataFrame({'번호':[temp_str_list[0]], '분류':[temp_str_list[1]], '제목':[temp_str_list[2]], \n",
    "                                     '만료일':[temp_str_list[3]], '참여인원':[temp_str_list[4]]}))\n",
    "            \n",
    "    page_num = page_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터프레임으로 병합\n",
    "df = pd.concat(my_list)\n",
    "# 인덱스 재정렬\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터프레임 엑셀로 저장\n",
    "save_excel(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
